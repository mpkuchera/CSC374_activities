{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba232a62-492c-4844-bc34-9a0807372177",
   "metadata": {},
   "source": [
    "# Gradient Descent Optimization \n",
    "\n",
    "In this activity, we will implement the gradient descent algorithm to find the minimum of an objective function that we want to minimize $J(x)$.\n",
    "\n",
    "$$J(x) = x^2 + 3x +4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1bd45-8dbc-49a9-9df7-80f507d486d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a265ebd-59a5-4d68-bde4-24047cbfcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the objective function and its derivative\n",
    "def J(x):\n",
    "\n",
    "\n",
    "def gradJ(x):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea966e7b-b8e1-4385-9d1f-2359436742e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot the Objective Function\n",
    "# (I chose to plot over the range [-10,10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977bb0bc-336b-43fd-9dc1-8cb8af12ac59",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "Next, we will implement gradient descent. As a reminder, our gradient descent algorithm is:\n",
    " 1. choose a starting point $x_0$\n",
    " 2. compute $\\frac{df}{dx}$\n",
    " 3. Update our point $x_i$ via\n",
    "    $x_{i+i} = x_i - \\eta \\frac{df}{dx}|_{x_0}$\n",
    " 4. Repeat steps 2. and 3. until converged.\n",
    "\n",
    "Play around with $\\eta$ and the tolerance (the convergence condition $|x_{i+1} - x_{i}|$) until you get a \"good\" result. We will invesitgate this more in the following cells.\n",
    "\n",
    "### Produce two plots: \n",
    "a. Plot the function using the same limits as above, and add a red dot for each $x_i$. \\\n",
    "b. Plot $f(x_i)$ as a function of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f26688-8ee0-4caa-9841-ecf88e240fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Implement gradient descent\n",
    "def gradient_descent(starting_point, learning_rate, tolerance, max_iterations):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04be807-7391-4910-913b-94a231444ca8",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "1. For a tolerance of $1\\times 10^{-6}$ and a starting point $x_0 = 10$, what is a suitable learning rate?\n",
    "2. What did you look at to determine this?\n",
    "3. How close is your answer to the true answer?\n",
    "4. In what ways is the objective function vs. iteration plot useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd0ab0-edef-4b9b-bab0-7c5217969ee4",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>\n",
    "\n",
    "\n",
    "Double click and type your responses here.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c8047-1e48-4a01-8899-b31aaac28622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
